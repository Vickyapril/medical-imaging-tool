{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6a370b6-554f-4d27-816b-a0e10c2cb3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import itk\n",
    "\n",
    "def load_dicom_image(filepath):\n",
    "    \"\"\"Loads a DICOM X-ray image and converts it to NumPy array\"\"\"\n",
    "    dicom_img = pydicom.dcmread(filepath)\n",
    "    return dicom_img.pixel_array\n",
    "\n",
    "def enhance_contrast(image):\n",
    "    \"\"\"Applies CLAHE contrast enhancement\"\"\"\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    return clahe.apply(image.astype(np.uint8))\n",
    "\n",
    "\n",
    "def itk_segmentation(image):\n",
    "    \"\"\"Performs basic segmentation using ITK\"\"\"\n",
    "    img_itk = itk.image_from_array(image)\n",
    "    smoothed = itk.SmoothingRecursiveGaussianImageFilter.New(Input=img_itk, Sigma=1.0)\n",
    "    smoothed.Update()\n",
    "    return itk.array_from_image(smoothed.GetOutput())\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c7b25ab-73b9-4b4d-80f6-b782c6f84eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Intensity: 91.59\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class SimulatedDetector:\n",
    "    def __init__(self):\n",
    "        self.noise_level = 0.1  # Simulated noise level\n",
    "\n",
    "    def get_intensity_reading(self):\n",
    "        \"\"\"Simulates real-time intensity readings\"\"\"\n",
    "        return round(100 + random.uniform(-self.noise_level, self.noise_level) * 100, 2)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    sensor = SimulatedDetector()\n",
    "    print(f\"Simulated Intensity: {sensor.get_intensity_reading()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb67abdb-f325-462e-891e-d154433485a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'image_processor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimage_processor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dicom_image, enhance_contrast\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mXRayViewer\u001b[39;00m(QWidget):\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'image_processor'"
     ]
    }
   ],
   "source": [
    "from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QPushButton, QFileDialog, QVBoxLayout\n",
    "import sys\n",
    "import cv2\n",
    "from image_processor import load_dicom_image, enhance_contrast\n",
    "\n",
    "class XRayViewer(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        self.setWindowTitle('XIMED X-Ray Viewer')\n",
    "        self.setGeometry(100, 100, 500, 400)\n",
    "\n",
    "        self.label = QLabel(\"Upload an X-ray Image\", self)\n",
    "        self.upload_btn = QPushButton(\"Load Image\", self)\n",
    "        self.upload_btn.clicked.connect(self.load_image)\n",
    "\n",
    "        self.process_btn = QPushButton(\"Enhance Image\", self)\n",
    "        self.process_btn.clicked.connect(self.process_image)\n",
    "\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.label)\n",
    "        layout.addWidget(self.upload_btn)\n",
    "        layout.addWidget(self.process_btn)\n",
    "        self.setLayout(layout)\n",
    "\n",
    "    def load_image(self):\n",
    "        filepath, _ = QFileDialog.getOpenFileName(self, \"Open DICOM Image\", \"\", \"DICOM Files (*.dcm);;PNG Files (*.png)\")\n",
    "        if filepath:\n",
    "            self.image = load_dicom_image(filepath)\n",
    "            self.label.setText(f\"Loaded: {filepath}\")\n",
    "\n",
    "    def process_image(self):\n",
    "        if hasattr(self, 'image'):\n",
    "            enhanced = enhance_contrast(self.image)\n",
    "            cv2.imshow(\"Enhanced Image\", enhanced)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    viewer = XRayViewer()\n",
    "    viewer.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1325b28c-3688-42d2-901d-ad222533c744",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'image_processor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimage_processor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enhance_contrast\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_enhance_contrast\u001b[39m():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124;03m\"\"\"Test contrast enhancement function\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'image_processor'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from image_processor import enhance_contrast\n",
    "\n",
    "def test_enhance_contrast():\n",
    "    \"\"\"Test contrast enhancement function\"\"\"\n",
    "    sample_img = np.ones((128, 128), dtype=np.uint8) * 100\n",
    "    enhanced = enhance_contrast(sample_img)\n",
    "    assert enhanced.shape == sample_img.shape, \"Output shape must match input shape\"\n",
    "    assert enhanced.mean() > sample_img.mean(), \"Contrast should be improved\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04c75fe0-6496-4e62-9fb2-efe366cc8341",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'image_processor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimage_processor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dicom_image, enhance_contrast\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'image_processor'"
     ]
    }
   ],
   "source": [
    "from image_processor import load_dicom_image, enhance_contrast\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dicom_path = \"data/sample_xray.dcm\"  # Update with your actual DICOM file path\n",
    "\n",
    "# Load the DICOM image\n",
    "try:\n",
    "    img = load_dicom_image(dicom_path)\n",
    "    print(\"DICOM image loaded successfully!\")\n",
    "\n",
    "    # Print image details\n",
    "    print(f\"Image data type: {img.dtype}, Min: {np.min(img)}, Max: {np.max(img)}\")\n",
    "\n",
    "    # Enhance contrast\n",
    "    enhanced_img = enhance_contrast(img)\n",
    "    print(\"Contrast enhancement applied successfully!\")\n",
    "\n",
    "    # Show original and enhanced images\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(img, cmap=\"gray\")\n",
    "    axes[0].set_title(\"Original X-ray\")\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(enhanced_img, cmap=\"gray\")\n",
    "    axes[1].set_title(\"Enhanced X-ray\")\n",
    "    axes[1].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb5411ce-d43b-4c13-8d29-ac69bfd19c8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m dicom_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/sample_xray.dcm\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21menhance_contrast\u001b[39m(image):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124;03m\"\"\"Applies CLAHE contrast enhancement to a grayscale medical image.\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "dicom_path = \"data/sample_xray.dcm\" \n",
    "print(f\"Image Shape: {image.shape}\")\n",
    "\n",
    "def enhance_contrast(image):\n",
    "    \"\"\"Applies CLAHE contrast enhancement to a grayscale medical image.\"\"\"\n",
    "    \n",
    "    # Convert to uint8 if necessary\n",
    "    if image.dtype != np.uint8:\n",
    "        print(f\"Converting image from {image.dtype} to uint8...\")\n",
    "        image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "    # Ensure single-channel grayscale image\n",
    "    if len(image.shape) > 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    return clahe.apply(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1bed4e0-69aa-4a4b-9327-52e2aad9d832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICOM image loaded successfully: data/sample_xray.dcm\n",
      "Image dtype: uint16, shape: (512, 512)\n",
      "Original image dtype: uint16, shape: (512, 512)\n",
      "Converting image from uint16 to uint8...\n",
      "Image for segmentation: dtype=uint8, shape=(512, 512)\n",
      "Segmentation completed. Image shape: (512, 512)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import itk\n",
    "\n",
    "def load_dicom_image(filepath):\n",
    "    \"\"\"Loads a DICOM X-ray image and converts it to NumPy array.\"\"\"\n",
    "    try:\n",
    "        dicom_img = pydicom.dcmread(filepath)\n",
    "        image = dicom_img.pixel_array\n",
    "        if image is None:\n",
    "            print(f\"Error: Failed to load pixel data from DICOM file: {filepath}\")\n",
    "            return None\n",
    "        print(f\"DICOM image loaded successfully: {filepath}\")\n",
    "        print(f\"Image dtype: {image.dtype}, shape: {image.shape}\")\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading DICOM file: {e}\")\n",
    "        return None\n",
    "\n",
    "def enhance_contrast(image):\n",
    "    \"\"\"Applies CLAHE contrast enhancement to a grayscale medical image.\"\"\"\n",
    "    \n",
    "    if image is None:\n",
    "        print(\"Error: Image is None.\")\n",
    "        return None\n",
    "    \n",
    "    # Print image shape and dtype for debugging\n",
    "    print(f\"Original image dtype: {image.dtype}, shape: {image.shape}\")\n",
    "    \n",
    "    # Ensure image is single-channel grayscale\n",
    "    if len(image.shape) > 2:\n",
    "        print(f\"Warning: Image has {image.shape[2]} channels, converting to grayscale.\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        print(f\"Converted to grayscale: {image.shape}\")\n",
    "    \n",
    "    # Convert to uint8 if the dtype is not uint8\n",
    "    if image.dtype != np.uint8:\n",
    "        print(f\"Converting image from {image.dtype} to uint8...\")\n",
    "        image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    \n",
    "    # Verify image dtype and range\n",
    "    if image.dtype != np.uint8:\n",
    "        print(f\"Error: Image must be uint8, but it is {image.dtype}.\")\n",
    "        return None\n",
    "    if np.min(image) < 0 or np.max(image) > 255:\n",
    "        print(f\"Warning: Image values are outside the expected [0, 255] range. Min: {np.min(image)}, Max: {np.max(image)}\")\n",
    "    \n",
    "    # Apply CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    enhanced_image = clahe.apply(image)\n",
    "    \n",
    "    return enhanced_image\n",
    "\n",
    "def itk_segmentation(image):\n",
    "    \"\"\"Performs basic segmentation using ITK\"\"\"\n",
    "    \n",
    "    if image is None:\n",
    "        print(\"Error: Image is None.\")\n",
    "        return None\n",
    "    \n",
    "    # Verify image type and shape before processing with ITK\n",
    "    print(f\"Image for segmentation: dtype={image.dtype}, shape={image.shape}\")\n",
    "    \n",
    "    # Convert the image to ITK format (ensure it's in the correct range and type)\n",
    "    img_itk = itk.image_from_array(image)\n",
    "    \n",
    "    # Perform smoothing (segmentation step, basic)\n",
    "    smoothed = itk.SmoothingRecursiveGaussianImageFilter.New(Input=img_itk, Sigma=1.0)\n",
    "    smoothed.Update()\n",
    "    \n",
    "    # Convert back to numpy array\n",
    "    segmented_image = itk.array_from_image(smoothed.GetOutput())\n",
    "    \n",
    "    print(f\"Segmentation completed. Image shape: {segmented_image.shape}\")\n",
    "    return segmented_image\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = \"data/sample_xray.dcm\"  # Provide your DICOM file path here\n",
    "    image = load_dicom_image(filepath)\n",
    "    \n",
    "    if image is not None:\n",
    "        # Enhance contrast\n",
    "        enhanced_image = enhance_contrast(image)\n",
    "        if enhanced_image is not None:\n",
    "            # Perform segmentation\n",
    "            segmented_image = itk_segmentation(enhanced_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8287d4d-6470-416b-93ef-8219e8696d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICOM image loaded successfully: /Users/vigneshwar.gurunatha/Desktop/xi-med/data/case2/case2b_004.dcm\n",
      "Image dtype: uint16, shape: (512, 512)\n",
      "DICOM image loaded successfully: /Users/vigneshwar.gurunatha/Desktop/xi-med/data/case2/case2b_001.dcm\n",
      "Image dtype: uint16, shape: (512, 512)\n",
      "DICOM image loaded successfully: /Users/vigneshwar.gurunatha/Desktop/xi-med/data/case2/case2b_003.dcm\n",
      "Image dtype: uint16, shape: (512, 512)\n",
      "DICOM image loaded successfully: /Users/vigneshwar.gurunatha/Desktop/xi-med/data/case2/case2b_002.dcm\n",
      "Image dtype: uint16, shape: (512, 512)\n",
      "DICOM image loaded successfully: /Users/vigneshwar.gurunatha/Desktop/xi-med/data/case2/case2a_003.dcm\n",
      "Image dtype: uint16, shape: (512, 512)\n",
      "DICOM image loaded successfully: /Users/vigneshwar.gurunatha/Desktop/xi-med/data/case2/case2a_002.dcm\n",
      "Image dtype: uint16, shape: (512, 512)\n",
      "DICOM image loaded successfully: /Users/vigneshwar.gurunatha/Desktop/xi-med/data/case2/case2a_001.dcm\n",
      "Image dtype: uint16, shape: (512, 512)\n",
      "Processing image 1/7\n",
      "Original image dtype: uint16, shape: (512, 512)\n",
      "Converting image from uint16 to uint8...\n",
      "Image for segmentation: dtype=uint8, shape=(512, 512)\n",
      "Segmentation completed. Image shape: (512, 512)\n",
      "Processing image 2/7\n",
      "Original image dtype: uint16, shape: (512, 512)\n",
      "Converting image from uint16 to uint8...\n",
      "Image for segmentation: dtype=uint8, shape=(512, 512)\n",
      "Segmentation completed. Image shape: (512, 512)\n",
      "Processing image 3/7\n",
      "Original image dtype: uint16, shape: (512, 512)\n",
      "Converting image from uint16 to uint8...\n",
      "Image for segmentation: dtype=uint8, shape=(512, 512)\n",
      "Segmentation completed. Image shape: (512, 512)\n",
      "Processing image 4/7\n",
      "Original image dtype: uint16, shape: (512, 512)\n",
      "Converting image from uint16 to uint8...\n",
      "Image for segmentation: dtype=uint8, shape=(512, 512)\n",
      "Segmentation completed. Image shape: (512, 512)\n",
      "Processing image 5/7\n",
      "Original image dtype: uint16, shape: (512, 512)\n",
      "Converting image from uint16 to uint8...\n",
      "Image for segmentation: dtype=uint8, shape=(512, 512)\n",
      "Segmentation completed. Image shape: (512, 512)\n",
      "Processing image 6/7\n",
      "Original image dtype: uint16, shape: (512, 512)\n",
      "Converting image from uint16 to uint8...\n",
      "Image for segmentation: dtype=uint8, shape=(512, 512)\n",
      "Segmentation completed. Image shape: (512, 512)\n",
      "Processing image 7/7\n",
      "Original image dtype: uint16, shape: (512, 512)\n",
      "Converting image from uint16 to uint8...\n",
      "Image for segmentation: dtype=uint8, shape=(512, 512)\n",
      "Segmentation completed. Image shape: (512, 512)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import itk\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def load_dicom_images_from_directory(directory):\n",
    "    \"\"\"Loads all DICOM X-ray images from a specified directory.\"\"\"\n",
    "    dicom_files = glob(os.path.join(directory, \"*.dcm\"))  # Get all .dcm files in the directory\n",
    "    if not dicom_files:\n",
    "        print(f\"No DICOM files found in directory: {directory}\")\n",
    "        return []\n",
    "    \n",
    "    images = []\n",
    "    for file in dicom_files:\n",
    "        try:\n",
    "            dicom_img = pydicom.dcmread(file)\n",
    "            image = dicom_img.pixel_array\n",
    "            if image is None:\n",
    "                print(f\"Error: Failed to load pixel data from DICOM file: {file}\")\n",
    "                continue\n",
    "            print(f\"DICOM image loaded successfully: {file}\")\n",
    "            print(f\"Image dtype: {image.dtype}, shape: {image.shape}\")\n",
    "            images.append(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading DICOM file {file}: {e}\")\n",
    "    \n",
    "    return images\n",
    "\n",
    "def enhance_contrast(image):\n",
    "    \"\"\"Applies CLAHE contrast enhancement to a grayscale medical image.\"\"\"\n",
    "    \n",
    "    if image is None:\n",
    "        print(\"Error: Image is None.\")\n",
    "        return None\n",
    "    \n",
    "    # Print image shape and dtype for debugging\n",
    "    print(f\"Original image dtype: {image.dtype}, shape: {image.shape}\")\n",
    "    \n",
    "    # Ensure image is single-channel grayscale\n",
    "    if len(image.shape) > 2:\n",
    "        print(f\"Warning: Image has {image.shape[2]} channels, converting to grayscale.\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        print(f\"Converted to grayscale: {image.shape}\")\n",
    "    \n",
    "    # Convert to uint8 if the dtype is not uint8\n",
    "    if image.dtype != np.uint8:\n",
    "        print(f\"Converting image from {image.dtype} to uint8...\")\n",
    "        image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    \n",
    "    # Verify image dtype and range\n",
    "    if image.dtype != np.uint8:\n",
    "        print(f\"Error: Image must be uint8, but it is {image.dtype}.\")\n",
    "        return None\n",
    "    if np.min(image) < 0 or np.max(image) > 255:\n",
    "        print(f\"Warning: Image values are outside the expected [0, 255] range. Min: {np.min(image)}, Max: {np.max(image)}\")\n",
    "    \n",
    "    # Apply CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "    enhanced_image = clahe.apply(image)\n",
    "    \n",
    "    return enhanced_image\n",
    "\n",
    "def itk_segmentation(image):\n",
    "    \"\"\"Performs basic segmentation using ITK\"\"\"\n",
    "    \n",
    "    if image is None:\n",
    "        print(\"Error: Image is None.\")\n",
    "        return None\n",
    "    \n",
    "    # Verify image type and shape before processing with ITK\n",
    "    print(f\"Image for segmentation: dtype={image.dtype}, shape={image.shape}\")\n",
    "    \n",
    "    # Convert the image to ITK format (ensure it's in the correct range and type)\n",
    "    img_itk = itk.image_from_array(image)\n",
    "    \n",
    "    # Perform smoothing (segmentation step, basic)\n",
    "    smoothed = itk.SmoothingRecursiveGaussianImageFilter.New(Input=img_itk, Sigma=1.0)\n",
    "    smoothed.Update()\n",
    "    \n",
    "    # Convert back to numpy array\n",
    "    segmented_image = itk.array_from_image(smoothed.GetOutput())\n",
    "    \n",
    "    print(f\"Segmentation completed. Image shape: {segmented_image.shape}\")\n",
    "    return segmented_image\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    directory = \"/Users/vigneshwar.gurunatha/Desktop/xi-med/data/case2\"  # Specify your directory with .dcm files\n",
    "    images = load_dicom_images_from_directory(directory)\n",
    "    \n",
    "    if images:\n",
    "        for idx, image in enumerate(images):\n",
    "            print(f\"Processing image {idx + 1}/{len(images)}\")\n",
    "            \n",
    "            # Enhance contrast\n",
    "            enhanced_image = enhance_contrast(image)\n",
    "            if enhanced_image is not None:\n",
    "                # Perform segmentation\n",
    "                segmented_image = itk_segmentation(enhanced_image)\n",
    "                \n",
    "                # Optionally save or process the segmented image further\n",
    "                # For example, save to a file\n",
    "                # cv2.imwrite(f\"segmented_image_{idx + 1}.png\", segmented_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec43526-758c-459e-be70-644f4a880427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class SimulatedDetector:\n",
    "    def __init__(self):\n",
    "        self.noise_level = 0.1  # Simulated noise level\n",
    "\n",
    "    def get_intensity_reading(self):\n",
    "        \"\"\"Simulates real-time intensity readings\"\"\"\n",
    "        return round(100 + random.uniform(-self.noise_level, self.noise_level) * 100, 2)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    sensor = SimulatedDetector()\n",
    "    print(f\"Simulated Intensity: {sensor.get_intensity_reading()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29778921-ae37-4432-90ef-c2524440778d",
   "metadata": {},
   "outputs": [],
   "source": [
    " def process_image(self):\n",
    "        if hasattr(self, 'image'):\n",
    "            print(\"Processing image...\")\n",
    "            enhanced = enhance_contrast(self.image)\n",
    "            if enhanced is not None:\n",
    "                print(\"Image enhanced successfully.\")\n",
    "                \n",
    "                # Convert the NumPy array to a QImage\n",
    "                height, width = enhanced.shape\n",
    "                bytes_per_line = width\n",
    "                q_img = QImage(enhanced.data, width, height, bytes_per_line, QImage.Format_Grayscale8)\n",
    "\n",
    "                # Convert to QPixmap for display\n",
    "                pixmap = QPixmap.fromImage(q_img)\n",
    "\n",
    "                # Update QLabel with the enhanced image\n",
    "                self.label.setPixmap(pixmap.scaled(400, 400, Qt.KeepAspectRatio))\n",
    "                self.label.setAlignment(Qt.AlignCenter)\n",
    "            else:\n",
    "                print(\"Error: Enhancement failed.\")\n",
    "                self.label.setText(\"Enhancement failed.\")\n",
    "        else:\n",
    "            print(\"No image to process.\")\n",
    "            self.label.setText(\"Please load an image first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96163ed-8b50-48f2-abdd-efbe5bce7644",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    def enhance_image(self):\n",
    "        if self.image is not None:\n",
    "            print(\"Enhancing image...\")  # Debug\n",
    "            print(f\"Image dtype before enhancement: {self.image.dtype}, shape: {self.image.shape}\")\n",
    "\n",
    "            self.processed_image = enhance_contrast(self.image)\n",
    "\n",
    "            if self.processed_image is not None:\n",
    "                print(\"Enhanced image dtype:\", self.processed_image.dtype)\n",
    "                self.show_image(self.processed_image, \"Enhanced X-ray\")\n",
    "            else:\n",
    "                print(\"Error: Enhancement failed.\")\n",
    "        else:\n",
    "            self.label.setText(\"Please load an image first.\")\n",
    "\n",
    "    def crop_image(self):\n",
    "        if self.image is not None:\n",
    "            x, ok1 = QInputDialog.getInt(self, \"Crop\", \"Enter X coordinate:\")\n",
    "            y, ok2 = QInputDialog.getInt(self, \"Crop\", \"Enter Y coordinate:\")\n",
    "            w, ok3 = QInputDialog.getInt(self, \"Crop\", \"Enter Width:\")\n",
    "            h, ok4 = QInputDialog.getInt(self, \"Crop\", \"Enter Height:\")\n",
    "            \n",
    "            if ok1 and ok2 and ok3 and ok4:\n",
    "                self.processed_image = crop_image(self.image, x, y, w, h)\n",
    "                self.show_image(self.processed_image, \"Cropped X-ray\")\n",
    "        else:\n",
    "            self.label.setText(\"Please load an image first.\")\n",
    "\n",
    "    def colorize_image(self):\n",
    "        if self.image is not None:\n",
    "            self.processed_image = apply_false_color(self.image)\n",
    "            self.show_image(self.processed_image, \"Colorized X-ray\")\n",
    "        else:\n",
    "            self.label.setText(\"Please load an image first.\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c2b6c-49ce-4c62-bf05-f1f978c951c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QPushButton, QFileDialog, QVBoxLayout,QMainWindow,QInputDialog\n",
    "from PyQt5.QtCore import Qt\n",
    "from image_processor import load_dicom_image, enhance_contrast,crop_image,apply_false_color,save_image\n",
    "\n",
    "class XRayViewer(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.image = None #Original image\n",
    "        self.cropped_image= None # Selected region\n",
    "        self.processed_image = None # Final output\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        self.setWindowTitle('Xi-Med Test Software')\n",
    "        self.setGeometry(100, 100, 600, 500)\n",
    "\n",
    "        self.label = QLabel(\"Upload a Dicom fle\", self)\n",
    "        self.upload_btn = QPushButton(\"Load file\", self)\n",
    "        self.upload_btn.clicked.connect(self.load_image)\n",
    "\n",
    "\n",
    "        #self.enhance_btn = QPushButton(\"Enhance Contrast\", self)\n",
    "        #self.enhance_btn.clicked.connect(self.enhance_image)\n",
    "\n",
    "        self.crop_btn = QPushButton(\"Select region\", self)\n",
    "        self.crop_btn.clicked.connect(self.select_region)\n",
    "\n",
    "        self.color_btn = QPushButton(\"Apply False Color\", self)\n",
    "        self.color_btn.clicked.connect(self.apply_colormap)\n",
    "\n",
    "        self.save_btn = QPushButton(\"Save Image\", self)\n",
    "        self.save_btn.clicked.connect(self.save_image)\n",
    "\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.label)\n",
    "        layout.addWidget(self.upload_btn)\n",
    "        #layout.addWidget(self.enhance_btn)\n",
    "        layout.addWidget(self.crop_btn)\n",
    "        layout.addWidget(self.color_btn)\n",
    "        layout.addWidget(self.save_btn)\n",
    "        self.setLayout(layout)\n",
    "\n",
    "    def load_image(self):\n",
    "        filepath, _ = QFileDialog.getOpenFileName(self, \"Open DICOM Image\", \"\", \"DICOM Files (*.dcm);;PNG Files (*.png)\")\n",
    "        if filepath:\n",
    "            if filepath.endswith(\".dcm\"):\n",
    "                self.image = load_dicom_image(filepath)\n",
    "            else:\n",
    "                self.image = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)  \n",
    "            \n",
    "            if self.image is not None:\n",
    "                self.label.setText(f\"Loaded: {filepath}\")\n",
    "                print(f\"Image loaded from: {filepath}\")\n",
    "            else:\n",
    "                self.label.setText(\"Failed to load image.\")\n",
    "                print(\"Failed to load image.\")\n",
    "        else:\n",
    "            print(\"No file selected.\")\n",
    "\n",
    "    def select_region(self):\n",
    "        if self.image is not None:\n",
    "            print(\"Select region with your mouse and press ENTER to confirm\")\n",
    "            img_copy = self.image.copy()\n",
    "            r = cv2.selectROI(\"Select Region\", img_copy, fromCenter=False, showCrosshair=True)\n",
    "            cv2.destroyWindow(\"Select Region\")\n",
    "\n",
    "            x, y, w, h = map(int, r)\n",
    "            print(f\"Selected region: x={x}, y={y}, width={w}, height={h}\")\n",
    "\n",
    "        # Crop the selected region\n",
    "            self.cropped_image = self.image[y:y+h, x:x+w]\n",
    "            self.show_image(self.cropped_image, \"Cropped Region\")\n",
    "        else:\n",
    "            self.label.setText(\"Please load an image first.\")\n",
    "\n",
    "    def apply_colormap(self):\n",
    "        if self.cropped_image is not None:\n",
    "            self.processed_image = apply_false_color(self.cropped_image)\n",
    "            self.show_image(self.processed_image, \"Colorized Region\")\n",
    "        else:\n",
    "            self.label.setText(\"Please select a region first.\")\n",
    "\n",
    "\n",
    "    def save_image(self):\n",
    "        if self.processed_image is not None:\n",
    "            filename, _ = QFileDialog.getSaveFileName(self, \"Save Image\", \"\", \"PNG Files (*.png)\")\n",
    "            if filename:\n",
    "                save_image(self.processed_image, filename)\n",
    "                self.label.setText(f\"Image saved: {filename}\")\n",
    "        else:\n",
    "            self.label.setText(\"Please process an image first.\")\n",
    "\n",
    "    def show_image(self, image, title):\n",
    "        plt.figure()\n",
    "        plt.imshow(image, cmap=\"gray\" if len(image.shape) == 2 else None)\n",
    "        plt.title(title)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show(block=False)\n",
    "\n",
    "\n",
    "   \n",
    "if __name__ == '__main__':\n",
    "   # app = QApplication(sys.argv)\n",
    "   app = QApplication([])\n",
    "   viewer = XRayViewer()\n",
    "   viewer.show()\n",
    "   app.exec_()\n",
    "    #sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bd09cb-4404-425a-aeb6-417324d782aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QLabel, QPushButton, QFileDialog, QVBoxLayout\n",
    "from PyQt5.QtGui import QPixmap, QImage\n",
    "from PyQt5.QtCore import Qt\n",
    "from image_processor import load_dicom_image, apply_false_color, save_image\n",
    "\n",
    "class XRayViewer(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.image = None  # Original image\n",
    "        self.cropped_image = None  # Selected region\n",
    "        self.processed_image = None  # Final output\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        self.setWindowTitle('XIMED X-Ray Viewer')\n",
    "        self.setGeometry(100, 100, 600, 500)\n",
    "\n",
    "        self.label = QLabel(\"Upload an X-ray Image\", self)\n",
    "\n",
    "        self.upload_btn = QPushButton(\"Load Image\", self)\n",
    "        self.upload_btn.clicked.connect(self.load_image)\n",
    "\n",
    "        self.crop_btn = QPushButton(\"Select Region\", self)\n",
    "        self.crop_btn.clicked.connect(self.select_region)\n",
    "\n",
    "        self.color_btn = QPushButton(\"Apply False Color\", self)\n",
    "        self.color_btn.clicked.connect(self.apply_colormap)\n",
    "\n",
    "        self.save_btn = QPushButton(\"Save Image\", self)\n",
    "        self.save_btn.clicked.connect(self.save_image)\n",
    "\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.label)\n",
    "        layout.addWidget(self.upload_btn)\n",
    "        layout.addWidget(self.crop_btn)\n",
    "        layout.addWidget(self.color_btn)\n",
    "        layout.addWidget(self.save_btn)\n",
    "        self.setLayout(layout)\n",
    "    def load_image(self):\n",
    "        filepath, _ = QFileDialog.getOpenFileName(self, \"Open Image\", \"\", \"DICOM Files (*.dcm);;PNG Files (*.png)\")\n",
    "        if filepath:\n",
    "            if filepath.endswith(\".dcm\"):\n",
    "                self.image = load_dicom_image(filepath)  # Load DICOM file\n",
    "            else:\n",
    "                self.image = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if self.image is not None:\n",
    "                print(f\"Image loaded successfully. Shape: {self.image.shape}, Dtype: {self.image.dtype}\")\n",
    "\n",
    "                # Check the pixel range\n",
    "                print(f\"Image pixel range: min={self.image.min()}, max={self.image.max()}\")\n",
    "\n",
    "                # If the image is of type uint16, normalize to uint8 for display\n",
    "                if self.image.dtype == np.uint16:\n",
    "                    print(\"Converting uint16 image to uint8...\")\n",
    "                    # Normalize the image to range 0-255\n",
    "                    image_normalized = cv2.normalize(self.image, None, 0, 255, cv2.NORM_MINMAX)\n",
    "                    self.image = image_normalized.astype(np.uint8)\n",
    "\n",
    "                print(f\"Processed image dtype: {self.image.dtype}, Shape: {self.image.shape}\")\n",
    "                \n",
    "                # Show image using OpenCV for debugging purposes\n",
    "                cv2.imshow(\"Loaded Image\", self.image)\n",
    "                cv2.waitKey(0)\n",
    "                cv2.destroyAllWindows()\n",
    "\n",
    "                # Update label with the file path\n",
    "                self.label.setText(f\"Loaded: {filepath}\")\n",
    "                self.show_image(self.image, \"Original Image\")\n",
    "            else:\n",
    "                print(\"Error: Image is None.\")\n",
    "                self.label.setText(\"Failed to load image.\")\n",
    "        else:\n",
    "            print(\"No file selected.\")\n",
    "\n",
    "    def select_region(self):\n",
    "        if self.image is not None:\n",
    "            print(\"Select region with your mouse and press ENTER to confirm\")\n",
    "            img_copy = self.image.copy()\n",
    "            r = cv2.selectROI(\"Select Region\", img_copy, fromCenter=False, showCrosshair=True)\n",
    "            cv2.destroyWindow(\"Select Region\")\n",
    "\n",
    "            # Check if region selection is valid (non-zero width and height)\n",
    "            x, y, w, h = map(int, r)\n",
    "            if w > 0 and h > 0:\n",
    "                print(f\"Selected region: x={x}, y={y}, width={w}, height={h}\")\n",
    "                # Crop the selected region\n",
    "                self.cropped_image = self.image[y:y+h, x:x+w]\n",
    "                self.show_image(self.cropped_image, \"Cropped Region\")\n",
    "            else:\n",
    "                print(\"Invalid region selected. Please select a valid region.\")\n",
    "                self.label.setText(\"Please select a valid region.\")\n",
    "        else:\n",
    "            self.label.setText(\"Please load an image first.\")\n",
    "\n",
    "\n",
    "    def apply_colormap(self):\n",
    "        if self.cropped_image is not None:\n",
    "            self.processed_image = apply_false_color(self.cropped_image)\n",
    "            self.show_image(self.processed_image, \"Colorized Region\")\n",
    "        else:\n",
    "            self.label.setText(\"Please select a region first.\")\n",
    "\n",
    "    def save_image(self):\n",
    "        if self.processed_image is not None:\n",
    "            filename, _ = QFileDialog.getSaveFileName(self, \"Save Image\", \"\", \"PNG Files (*.png)\")\n",
    "            if filename:\n",
    "                save_image(self.processed_image, filename)\n",
    "                self.label.setText(f\"Image saved: {filename}\")\n",
    "        else:\n",
    "            self.label.setText(\"Please process an image first.\")\n",
    "\n",
    "    def show_image(self, image, title):\n",
    "        \"\"\"Display the image in a QLabel.\"\"\"\n",
    "        # Convert NumPy array to QImage\n",
    "        if len(image.shape) == 2:  # Grayscale image\n",
    "            q_img = QImage(image.data, image.shape[1], image.shape[0], image.shape[1], QImage.Format_Grayscale8)\n",
    "        else:  # Color image (for false color)\n",
    "            q_img = QImage(image.data, image.shape[1], image.shape[0], image.shape[1] * 3, QImage.Format_RGB888)\n",
    "\n",
    "        pixmap = QPixmap.fromImage(q_img)\n",
    "        self.label.setPixmap(pixmap.scaled(400, 400, Qt.KeepAspectRatio))\n",
    "        self.label.setAlignment(Qt.AlignCenter)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication([])\n",
    "    viewer = XRayViewer()\n",
    "    viewer.show()\n",
    "    app.exec_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294b988a-6414-4934-81c7-3a4b4cec6eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_contrast(image):\n",
    "    \"\"\"Applies CLAHE contrast enhancement to a grayscale medical image.\"\"\"\n",
    "    \n",
    "    if image is None:\n",
    "        print(\"Error: Image is None.\")\n",
    "        return None\n",
    "    \n",
    "    # Print image shape and dtype for debugging\n",
    "    print(f\"Original image dtype: {image.dtype}, shape: {image.shape}\")\n",
    "    \n",
    "    # Ensure image is single-channel grayscale\n",
    "    if len(image.shape) > 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        print(f\"Converted to grayscale: {image.shape}\")\n",
    "    \n",
    "    # Convert to uint8 if the dtype is not uint8\n",
    "    if image.dtype != np.uint8:\n",
    "        print(f\"Converting image from {image.dtype} to uint8...\")\n",
    "        image = (image - image.min()) / (image.max() - image.min())  # Normalize to 0-1\n",
    "        image = (image * 255).astype(np.uint8)  # Scale to 0-255\n",
    "        #image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    \n",
    "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "    clahe = cv2.createCLAHE(clipLimit=6.0, tileGridSize=(8, 8))\n",
    "    enhanced_image = clahe.apply(image)\n",
    "    \n",
    "    # Check enhancement result\n",
    "    if np.array_equal(enhanced_image, image):\n",
    "        print(\"Warning: Enhancement result is identical to the original image.\")\n",
    "    \n",
    "    return enhanced_image\n",
    "\n",
    "def crop_image(image, x, y, w, h):\n",
    "    \"\"\"Crops the image based on given coordinates\"\"\"\n",
    "    return image[y:y+h, x:x+w]\n",
    "\n",
    "\n",
    "def apply_false_color(image):\n",
    "    \"\"\"Applies a false color map to enhance visualization.\"\"\"\n",
    "    \n",
    "    # Ensure image is in uint8 format\n",
    "    if image.dtype != np.uint8:\n",
    "        print(f\"Converting image from {image.dtype} to uint8 for color mapping...\")\n",
    "        image = (255 * (image - image.min()) / (image.max() - image.min())).astype(np.uint8)\n",
    "\n",
    "    # Convert grayscale to 3-channel before applying color map\n",
    "    if len(image.shape) == 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Apply false color\n",
    "    return cv2.applyColorMap(image, cv2.COLORMAP_JET)\n",
    "\n",
    "def save_image(image, filename):\n",
    "    \"\"\"Saves the processed image to a file\"\"\"\n",
    "    cv2.imwrite(filename, image)\n",
    "\n",
    "def itk_segmentation(image):\n",
    "    \"\"\"Performs basic segmentation using ITK\"\"\"\n",
    "    img_itk = itk.image_from_array(image)\n",
    "    smoothed = itk.SmoothingRecursiveGaussianImageFilter.New(Input=img_itk, Sigma=1.0)\n",
    "    smoothed.Update()\n",
    "    return itk.array_from_image(smoothed.GetOutput())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
